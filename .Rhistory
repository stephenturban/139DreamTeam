"%/5%" <- function(x,y) (x*y*y*y) %%5  #division
#Given matrix A
r1 <- c(3,0,4,0,2,2); r2 <- c(1,1,3,3,2,1); r3 <- c(0,2,1,1,4,2); r4 <- c(1,0,2,0,3,4)
A <- rbind(r1, r2, r3, r4); A
#First I swap the first and the last rows.
temp <- A[1,]; A[1,] <- A[4,]; A[4,] <- temp; A_rr
#Add the 3 times the fourth row to the second row
A[2,] <- A[2,] %+5% (5%*5% A[4,]); A_rr
A[2,] <- A[2,] %*5% 5; A_rr
A[4,] <- A[4,] %*5% 5; A_rr
#First I swap the second and the third rows
temp <- A[2,]; A[2,] <- A[3,]; A[3,] <- temp; A_rr
#Divide second row by 2
A[2,] <- A[2,] %/5% 2; A_rr
#Basis for the image A
#In the row reduced matrix A, the first and second columns are pivotal.
#So the first and second columns of the orginal matrix are a basis for Img A.
#Basis for the Kernal of A
#To find a basis for the kernel, we will use the two nonpivotal columns.
#Vectors (x1 y1 1 0 0 0) and (x2 y2 0 1 0 0) must be independent,
#because no linear combination can have 0 as its 3rd and 4th component.
#The top row of the row reduced matrix applied to (x1 y1 1 0 0 0 ) says that x1+2 = 0.
#The second row of the row reduced matrix applied to (x1 y1 1 0 0 0) says that y1+3 = 0.
k1 <- c(-2,-3, 0, 0, 0, 0)   #first basis vector for the kernel
A%*%k1     #yes, it is in the kernel
A_rr    #the row reduced matrix
#The t
#Given matrix A
r1 <- c(3,0,4,0,2,2); r2 <- c(1,1,3,3,2,1); r3 <- c(0,2,1,1,4,2); r4 <- c(1,0,2,0,3,4)
A <- rbind(r1, r2, r3, r4); A
#First I swap the first and the last rows.
temp <- A[1,]; A[1,] <- A[4,]; A[4,] <- temp; temp
# We will be working in Z_5
"%+5%" <- function(x,y) (x+y) %%5  #addition
"%-5%" <- function(x,y) (x-y) %%5  #subtraction
"%*5%" <- function(x,y) (x*y) %%5  #multiplication
"%/5%" <- function(x,y) (x*y*y*y) %%5  #division
#Given matrix A
r1 <- c(3,0,4,0,2,2); r2 <- c(1,1,3,3,2,1); r3 <- c(0,2,1,1,4,2); r4 <- c(1,0,2,0,3,4)
A <- rbind(r1, r2, r3, r4); A
A_rref <- rbind(r1, r2, r3, r4); A_rref
#First I swap the first and the last rows.
temp <- A_rref[1,]; A_rref[1,] <- A_rref[4,]; A_rref[4,] <- temp; A_rref
#Add the 3 times the fourth row to the second row
A_rref[2,] <- A_rref[2,] %+5% (5%*5% A_rref[4,]); A_rref
A_rref[2,] <- A_rref[2,] %*5% 5; A_rref
A_rref[4,] <- A_rref[4,] %*5% 5; A_rref
#First I swap the second and the third rows
temp <- A_rref[2,]; A_rref[2,] <- A_rref[3,]; A_rref[3,] <- temp; A_rref
#Divide second row by 2
A_rref[2,] <- A_rref[2,] %/5% 2; A_rref
#Basis for the image A
#In the row reduced matrix A, the first and second columns are pivotal.
#So the first and second columns of the orginal matrix are a basis for Img A.
#Basis for the Kernal of A
#To find a basis for the kernel, we will use the two nonpivotal columns.
#Vectors (x1 y1 1 0 0 0) and (x2 y2 0 1 0 0) must be independent,
#because no linear combination can have 0 as its 3rd and 4th component.
#The top row of the row reduced matrix applied to (x1 y1 1 0 0 0 ) says that x1+2 = 0.
#The second row of the row reduced matrix applied to (x1 y1 1 0 0 0) says that y1+3 = 0.
k1 <- c(-2,-3, 0, 0, 0, 0)   #first basis vector for the kernel
A%*%k1     #yes, it is in the kernel
A_rref #the row reduced matrix
A%*5%k1
# We will be working in Z_5
"%+5%" <- function(x,y) (x+y) %%5  #addition
"%-5%" <- function(x,y) (x-y) %%5  #subtraction
"%*5%" <- function(x,y) (x*y) %%5  #multiplication
"%/5%" <- function(x,y) (x*y*y*y) %%5  #division
#Given matrix A
r1 <- c(3,0,4,0,2,2); r2 <- c(1,1,3,3,2,1); r3 <- c(0,2,1,1,4,2); r4 <- c(1,0,2,0,3,4)
A <- rbind(r1, r2, r3, r4); A
A_rref <- rbind(r1, r2, r3, r4); A_rref
#First I swap the first and the last rows.
temp <- A_rref[1,]; A_rref[1,] <- A_rref[4,]; A_rref[4,] <- temp; A_rref
#Add the 3 times the fourth row to the second row
A_rref[2,] <- A_rref[2,] %+5% (5%*5% A_rref[4,]); A_rref
A_rref[2,] <- A_rref[2,] %*5% 5; A_rref
A_rref[4,] <- A_rref[4,] %*5% 5; A_rref
#First I swap the second and the third rows
temp <- A_rref[2,]; A_rref[2,] <- A_rref[3,]; A_rref[3,] <- temp; A_rref
#Divide second row by 2
A_rref[2,] <- A_rref[2,] %/5% 2; A_rref
#Basis for the image A
#In the row reduced matrix A, the first and second columns are pivotal.
#So the first and second columns of the orginal matrix are a basis for Img A.
#Basis for the Kernal of A
#To find a basis for the kernel, we will use the two nonpivotal columns.
#Vectors (x1 y1 1 0 0 0 ) and (x2 y2 0 1 0 0) must be independent,
#because no linear combination can have 0 as its 3rd and 4th component.
#The top row of the row reduced matrix applied to (x1 y1 1 0 0 0 ) says that x1+2 = 0.
#The second row of the row reduced matrix applied to (x1 y1 1 0 0 0) says that y1+3 = 0.
k1 <- c(-2,-3, 0, 0, 0, 0)   #first basis vector for the kernel
A%*5%k1     #yes, it is in the kernel
A_rref #the row reduced matrix
#The top row of the row reduced matrix applied to (x2 y2 0 1 0 0) says that x2 = 0.
#The second row of the row reduced matrix applied to (x2 y2 0 1 0 0) says that y2+3 = 0.
k2 <- c(0,-3,0,0, 0,0)   #second basis vector for the kernel
A%*5%k2     #yes, it is also in the kernel
w1 <- c(1,1,1)  #lies along the diagonal of the cube
w2 <- c(1,0,1)  #lies along a face diagonal of the cube
w3 <- c(3,4,12)  #has length 13
#Check for independence by row reduction.
rref(cbind(w1,w2,w3))
#If we accidentally chose a linearly dependent set, the dependence would become apparent.
#Step 1: make the first unit vector by normalization
v1 <- w1/Norm(w1); v1; Norm(v1)
#Step 2: convert w2 to a vector that is orthogonal to v1
x <- w2 - (w2%.%v1)*v1; x%.% v1
#Then convert x to a unit vector
v2 <- x/Norm(x); v2
#Step 3: convert w3 to a vector that is orthogonal to both v1 and v2
x <- w3 - (w3%.%v1)*v1 - (w3%.%v2)*v2; x%.% v1; x%.% v2
#Then convert x to a unit vector
v3 <- x/Norm(x); v3
#The easy way to check that we have succeeded:
R <- cbind(v1,v2, v3) ;R  #basis vectors are the columns
round(t(R)%*%R, digits = 6)   #the identity matrix
#Topic 3 - testing the cross-product rule for isometries
#The matrix R is an isometry - rotation or not?
det(R)   #+1 means that it's a rotation
det(R)
w1 <- c(1,1,1)  #lies along the diagonal of the cube
w2 <- c(1,0,1)  #lies along a face diagonal of the cube
w3 <- c(3,4,12)  #has length 13
#Check for independence by row reduction.
rref(cbind(w1,w2,w3))
#If we accidentally chose a linearly dependent set, the dependence would become apparent.
#Step 1: make the first unit vector by normalization
v1 <- w1/Norm(w1); v1; Norm(v1)
#Step 2: convert w2 to a vector that is orthogonal to v1
x <- w2 - (w2%.%v1)*v1; x%.% v1
#Then convert x to a unit vector
v2 <- x/Norm(x); v2
#Step 3: convert w3 to a vector that is orthogonal to both v1 and v2
x <- w3 - (w3%.%v1)*v1 - (w3%.%v2)*v2; x%.% v1; x%.% v2
#Then convert x to a unit vector
v3 <- x/Norm(x); v3
#The easy way to check that we have succeeded:
R <- cbind(v1,v3, v2) ;R  #basis vectors are the columns
round(t(R)%*%R, digits = 6)   #the identity matrix
#The matrix R is an isometry - rotation or not?
det(R)   #+1 means that it's a rotation
T_R <- t(R); T_R
EInv <- solve(E); EInv
T_R <- t(R); T_R
RInv <- solve(R); RInv
#Last modified September 17, 2014 by Paul Bamberg
par(mar=c(2,2,1,1)+0.1)
plot(NULL,xlim=c(-4,4),ylim=c(-4,4), xlab="", ylab="",axes = FALSE, asp = 1)
axis(1,pos=0); axis(2,pos=0)
#Topic 1 - Eigenvectors for a 2x2 matrix
#Here is the matrix from the Executive Summary
A <-matrix(c(-1,-2,4,5),2); A
#Let's see what it does to various vectors
#The direction of a standard basis vector gets changed
v1 <- c(1,0); w1 <- A%*%v1
arrows(0,0,v1[1],v1[2], col="red", lty = 2);arrows(0,0,w1[1],w1[2], col="red")
#The director of almost any other vector also gets changed
v2 <- c(0.6,-0.4); w2 <- A%*%v2
arrows(0,0,v2[1],v2[2], col="blue", lty = 2);arrows(0,0,w2[1],w2[2], col="blue")
#Math 23 Quizchooser2-23a.R
#Choose set 1,2, or 3 for the first four questions:
w <- sample(c("1","2","3",sample(c("1","2","3"),1)))
paste("Week 5, Section problem like set",w[1])
paste("Week 6, Section problem like set",w[2])
paste("Week 7, Section problem like set",w[3])
paste("Week 8, Section problem like set",w[4])
#Generate a permutation of 1234
perm <- sample(1:4);perm
#Choose one of the Week 5 proofs
c("5.1","5.2","5.3","5.4")[perm[1]]
#Choose one of the Week 6 proofs
c("6.1","6.2","6.3","6.4")[perm[2]]
#Choose one of the Week 7 proofs
c("7.1","7.2","7.3","7.4")[perm[3]]
#Choose one of the Week 7 proofs
c("8.1","8.2","8.3","8.4")[perm[4]]
#Choose the week for the extra proof
w<-sample(5:8,1)
#Choose the number of the extra proof
ord<-sample(c("first","second","third"),1)
paste("Week",w, ", the",ord,"proof not yet included")
fname=file.choose()
data=read.csv(fname,header=T)
? length
data[]
for(i in 1:length(data)) {
i_num <- lapply(colnames(data), as.numeric)
}
warnings()
mode(data$UGDS_num)
mode(data$UGDS_ASIAN_num)
mode(data$UGDS_ASIAN)
for(i in 1:length(data)) {
names < - c(colnames(data))
names(i) <- lapply(colnames(data), as.numeric)
}
names < - c(colnames(data))
for(i in 1:length(data)) {
names[i] <- lapply(colnames(data), as.numeric)
}
colnames(data)
names < - colnames(data)
for(i in 1:length(data)) {
names(i) <- lapply(colnames(data), as.numeric)
}
names <- colnames(data)
for(i in 1:length(data)) {
names(i) <- lapply(colnames(data), as.numeric)
}
names
names <- colnames(data)
for(i in 1:length(names)) {
names(i) <- lapply(names, as.numeric)
}
name(2)
names = colnames(data)
names(1)
names[8]
names = colnames(data)
for(i in 1:length(names)) {
names[i] <- lapply(names, as.numeric)
}
names = colnames(data)
for(i in 1:length(names)) {
names[i] = lapply(names, as.numeric)
names[i]= names[i]_NUM
}
names = colnames(data)
for(i in 1:length(names)){
names[i] = lapply(names, as.numeric)
names[i] <- "names[i]_NUM"
}
mode(data$PCIP26_NUM)
data$PCIP26_NUM
names = colnames(data)
for(i in 1:length(names)){
names[i] = lapply(names, as.numeric)
names[i] <- c(names[i],"_NUM")
}
mode(data$PCIP26_NUM)
names[1]
names = colnames(data)
names[1]
length(names)
names[122]
names[1] <- c(names[1], "_NUM")
names[1] <- c("_NUM")
names[1]
names[1]
names[2]
names[2] = lapply(names, as.numeric)
mode(data$names[2])
? mode
#function that calls all the variable names
names = colnames(data)
#For loop that turns variables into numeric and then changes name to columname_NUM
for(i in 1:length(names)){
names[i] = lapply(names, as.numeric)
names[i] <- paste(names[i], "_NUM")
}
names[4]
names[8]
names = colnames(data)
names[1]
f <-function(v) c(v[1]^(3/4)*v[2]^(1/3)+v[1], v[1]^(1/4)*v[2]^(2/3)+v[2])
v0 = c(16,8); f(v0)
A <- jacobian(f, v0); A
install.packages("numDeriv")
library(numDeriv)    #for the grad() function
par(mar = c(2,2,1,1))  #maximize space for graphs
f <-function(v) c(v[1]^(3/4)*v[2]^(1/3)+v[1], v[1]^(1/4)*v[2]^(2/3)+v[2])
v0 = c(16,8); f(v0)
A <- jacobian(f, v0); A
AInv =solve(A); AInv
v1 <- v0 - AInv%*%f(v0); v1; f(v1)
A <- jacobian(f, v1)
v2 <- v1 - solve(A)%*%f(v1); v2; f(v2)
A <- jacobian(f, v2)
v3 <- v2 - solve(A)%*%f(v2); f(v3)
v3
f(v0)
v1 = c(24,24)
v1 <- v0 + AInv%*%f(v0); v1; f(v1)
A <- jacobian(f, v1)
v2 <- v1 - solve(A)%*%f(v1); v2; f(v2)
f(v0 - v1)
v1 = c(24,24)
f(v0 - v1)
v0-v1
f <-function(v) c(v[1]^(3/4)*v[2]^(1/3)+v[1], v[1]^(1/4)*v[2]^(2/3)+v[2])
v0 = c(32,16); f(v0)
A <- jacobian(f, v0); A
AInv =solve(A); AInv
v1 <- v0 + AInv%*%f(v0); v1; f(v1)
A <- jacobian(f, v1)
v2 <- v1 - solve(A)%*%f(v1); v2; f(v2)
f <-function(v) c(v[1]^(3/4)*v[2]^(1/3)+v[1]-32, v[1]^(1/4)*v[2]^(2/3)+v[2]-16)
v0 = c(16,8); f(v0)
A <- jacobian(f, v0); A
AInv =solve(A); AInv
v1 <- v0 + AInv%*%f(v0); v1; f(v1)
A <- jacobian(f, v1)
v2 <- v1 - solve(A)%*%f(v1); v2; f(v2)
A <- jacobian(f, v2)
v3 <- v2 - solve(A)%*%f(v2); f(v3)
v3
v1 <- v0 - AInv%*%f(v0); v1; f(v1)
v1 = c(24,24)
v1 <- v0 - AInv%*%f(v0); v1; f(v1)
v0
v1
v1 = c(24,24)
v1
v0
v1 <- v0 - AInv%*%f(v0); v1; f(v1)
v1
f(v0)
v0 = c(14,10); f(v0)
v0 = c(24,24); f(v0)
v0 = c(15,9); f(v0)
A <- jacobian(f, v0); A
AInv =solve(A); AInv
v1 <- v0 - AInv%*%f(v0); v1; f(v1)
A <- jacobian(f, v1)
v2 <- v1 - solve(A)%*%f(v1); v2; f(v2)
A <- jacobian(f, v2)
v3 <- v2 - solve(A)%*%f(v2); f(v3)
v3
f <-function(v) c(v[1]^(3/4)*v[2]^(1/3)+v[1]-24, v[1]^(1/4)*v[2]^(2/3)+v[2]-24)
v0 = c(16,8); f(v0)
A <- jacobian(f, v0); A
AInv =solve(A); AInv
v1 <- v0 - AInv%*%f(v0); v1; f(v1)
A <- jacobian(f, v1)
v2 <- v1 - solve(A)%*%f(v1); v2; f(v2)
A <- jacobian(f, v2)
v3 <- v2 - solve(A)%*%f(v2); f(v3)
v3
f <- function(x) x(x^2 - 1)(x^2 - 4) -1
curve(f(x), from = 1, to = 2)
f <- function(x) x*(x^2 - 1)*(x^2 - 4)-1
f
f(x)
curve(f(x), from = 1, to = 2)
abline(h=0, col = "green")
curve(f(x), from = -5, to = 5)
curve(f(x), from = 1, to = 2)
curve(f(x), from = -5, to = 5)
f <- function(x) x*(x^2 - 1)*(x^2 - 4)-1
f(x)
curve(f(x), from = -5, to = 5)
x0 <- 1.2; f(x0); grad(f, x0)
curve(f(x0) + grad(f, x0)*(x-x0), col = "red", add = TRUE)
x1 <- x0 - f(x0)/grad(f, x0); abline(v = x1, col = "red"); f(x1)
x2 <- x1 - f(x1)/grad(f, x1); abline(v = x2, col = "red", lty = 2); f(x2)
x3 <- x2 - f(x2)/grad(f, x2); abline(v = x3, col = "red", lty = 3); f(x3)
x3
curve(f(x))
curve(f(x) from -4 to 4)
? curve
curve(f(x), from -4 to 4)
curve(f(x), from= -4, to= 4)
x0 <- -2; f(x0); grad(f, x0)
curve(f(x0) + grad(f, x0)*(x-x0), col = "red", add = TRUE)
x1 <- x0 - f(x0)/grad(f, x0); abline(v = x1, col = "red"); f(x1)
#Repeat to improve the approximation
x2 <- x1 - f(x1)/grad(f, x1); abline(v = x2, col = "red", lty = 2); f(x2)
x3 <- x2 - f(x2)/grad(f, x2); abline(v = x3, col = "red", lty = 3); f(x3)
x3
x4 <- -1; f(x4); grad(f, x4)
curve(f(x4) + grad(f, x4)*(x-x4), col = "red", add = TRUE)
x5 <- x4 - f(x4)/grad(f, x4); abline(v = x5, col = "red"); f(x5)
x6 <- x5 - f(x5)/grad(f, x5); abline(v = x6, col = "red", lty = 2); f(x6)
x7 <- x6 - f(x6)/grad(f, x6); abline(v = x7, col = "red", lty = 3); f(x7)
x7
x8 <- 0; f(x8); grad(f, x8)
#Add the tangent line to the plot
curve(f(x8) + grad(f, x8)*(x-x8), col = "red", add = TRUE)
x9 <- x8 - f(x8)/grad(f, x8); abline(v = x9, col = "red"); f(x9)
x10 <- x9 - f(x9)/grad(f, x9); abline(v = x10, col = "red", lty = 2); f(x10)
x11 <- x10 - f(x10)/grad(f, x10); abline(v = x11, col = "red", lty = 3); f(x11)
x11
x12 <- 1; f(x12); grad(f, x12)
curve(f(x12) + grad(f, x12)*(x-x12), col = "red", add = TRUE)
x13 <- x12 - f(x12)/grad(f, x12); abline(v = x13, col = "red"); f(x13)
x14 <- x13 - f(x13)/grad(f, x13); abline(v = x14, col = "red", lty = 2); f(x14)
x15 <- x14 - f(x14)/grad(f, x14); abline(v = x15, col = "red", lty = 3); f(x15)
x15
x16 <- 2; f(x16); grad(f, x16)
curve(f(x16) + grad(f, x16)*(x-x16), col = "red", add = TRUE)
x17 <- x16 - f(x16)/grad(f, x16); abline(v = x17, col = "red"); f(x17)
x18 <- x17 - f(x17)/grad(f, x17); abline(v = x18, col = "red", lty = 2); f(x18)
x19 <- x18 - f(x18)/grad(f, x18); abline(v = x19, col = "red", lty = 3); f(x19)
x19
plot?
?
? plot
? plot()
f <-function(v) c(v[1]^(3/4)*v[2]^(1/3)+v[1]-24, v[1]^(1/4)*v[2]^(2/3)+v[2]-24)
v0 = c(16,8); f(v0)
#The jacobian matrix and its inverse
A <- jacobian(f, v0); A
AInv =solve(A); AInv
#Formula for solving for the approximate solutions to the problem
#v1 = c(24,24)
v1 <- v0 - AInv%*%f(v0); v1; f(v1)
#Repeat to improve the approximation
A <- jacobian(f, v1)
v2 <- v1 - solve(A)%*%f(v1); v2; f(v2)
A <- jacobian(f, v2)
v3 <- v2 - solve(A)%*%f(v2); f(v3)
v3
#Problem 10
#Question: Get all five roots of x(x^2-1)(x^2-4) -1 =0 using Newton's method
#carry out enough iterations to get an error of less than .001
#Define the function
#x(x^2-1)(x^2-4) -1 =0
f <- function(x) x*(x^2 - 1)*(x^2 - 4)-1
f(x)
#graph of function
curve(f(x), from= -4, to= 4)
#Find for value for the first root
x0 <- -2; f(x0); grad(f, x0)
#Add the tangent line to the plot
curve(f(x0) + grad(f, x0)*(x-x0), col = "red", add = TRUE)
#Solve a linear approximation to find where the tangent line is zero
x1 <- x0 - f(x0)/grad(f, x0); abline(v = x1, col = "red"); f(x1)
#Repeat to improve the approximation
x2 <- x1 - f(x1)/grad(f, x1); abline(v = x2, col = "red", lty = 2); f(x2)
x3 <- x2 - f(x2)/grad(f, x2); abline(v = x3, col = "red", lty = 3); f(x3)
x3
#Find a value for the second root
x4 <- -1; f(x4); grad(f, x4)
#Add the tangent line to the plot
curve(f(x4) + grad(f, x4)*(x-x4), col = "red", add = TRUE)
#Solve a linear approximation to find where the tangent line is zero
x5 <- x4 - f(x4)/grad(f, x4); abline(v = x5, col = "red"); f(x5)
#Repeat to improve the approximation
x6 <- x5 - f(x5)/grad(f, x5); abline(v = x6, col = "red", lty = 2); f(x6)
x7 <- x6 - f(x6)/grad(f, x6); abline(v = x7, col = "red", lty = 3); f(x7)
x7
#Find a value for the third root
x8 <- 0; f(x8); grad(f, x8)
#Add the tangent line to the plot
curve(f(x8) + grad(f, x8)*(x-x8), col = "red", add = TRUE)
#Solve a linear approximation to find where the tangent line is zero
x9 <- x8 - f(x8)/grad(f, x8); abline(v = x9, col = "red"); f(x9)
#Repeat to improve the approximation
x10 <- x9 - f(x9)/grad(f, x9); abline(v = x10, col = "red", lty = 2); f(x10)
x11 <- x10 - f(x10)/grad(f, x10); abline(v = x11, col = "red", lty = 3); f(x11)
x11
#Find a value for the fourth root
x12 <- 1; f(x12); grad(f, x12)
#Add the tangent line to the plot
curve(f(x12) + grad(f, x12)*(x-x12), col = "red", add = TRUE)
#Solve a linear approximation to find where the tangent line is zero
x13 <- x12 - f(x12)/grad(f, x12); abline(v = x13, col = "red"); f(x13)
#Repeat to improve the approximation
x14 <- x13 - f(x13)/grad(f, x13); abline(v = x14, col = "red", lty = 2); f(x14)
x15 <- x14 - f(x14)/grad(f, x14); abline(v = x15, col = "red", lty = 3); f(x15)
x15
#Find a value for the fifth root
x16 <- 2; f(x16); grad(f, x16)
#Add the tangent line to the plot
curve(f(x16) + grad(f, x16)*(x-x16), col = "red", add = TRUE)
#Solve a linear approximation to find where the tangent line is zero
x17 <- x16 - f(x16)/grad(f, x16); abline(v = x17, col = "red"); f(x17)
#Repeat to improve the approximation
x18 <- x17 - f(x17)/grad(f, x17); abline(v = x18, col = "red", lty = 2); f(x18)
x19 <- x18 - f(x18)/grad(f, x18); abline(v = x19, col = "red", lty = 3); f(x19)
x19
f <-function(v) c(v[1]^(3/4)*v[2]^(1/3)+v[1]-24, v[1]^(1/4)*v[2]^(2/3)+v[2]-24)
v0 = c(16,8); f(v0)
#The jacobian matrix and its inverse
A <- jacobian(f, v0); A
AInv =solve(A); AInv
#Formula for solving for the approximate solutions to the problem
#v1 = c(24,24)
v1 <- v0 - AInv%*%f(v0); v1; f(v1)
#Repeat to improve the approximation
A <- jacobian(f, v1)
v2 <- v1 - solve(A)%*%f(v1); v2; f(v2)
A <- jacobian(f, v2)
v3 <- v2 - solve(A)%*%f(v2); f(v3)
v3
f <-function(v) c(v[1]^(3/4)*v[2]^(1/3)+v[1]-24, v[1]^(1/4)*v[2]^(2/3)+v[2]-24)
f(c(16,8)) #it works: H(appiness)=22, Cost= 11
x <- seq(from = 12, to = 18, by = 0.6)
y <- seq(from = 6, to = 10, by = 0.2)
V <- function(v) f(v)[1]
z <- matrix(apply(pairs,1,H),length(x)) #apply the happiness function
z <- matrix(apply(pairs,1,V),length(x)) #apply the happiness function
dim(x)
x <- seq(from = 12, to = 18)
y <- seq(from = 6, to = 10)
pairs <- expand.grid(x,y)  #a list of all pairs of values
V <- function(v) f(v)[1]
z <- matrix(apply(pairs,1,V),length(x)) #apply the happiness function
contour( x, y, z, asp = 1, nlevels = 20)    #shows contour lines
#Now do the same for the cost function
P <- function(v) f(v)[2]
z <- matrix(apply(pairs,1,P),length(x))
contour( x, y, z, asp = 1, add = TRUE, col = "red")    #shows contour lines
fJ <- jacobian(f, c(16,8));fJ
fInvJ <- solve(fJ); fInvJ
increment <- c(-8,8)    #happiness 22->19 , cost 11->10
c(16,8)+fInvJ%*%increment
setwd("~/139DreamTeam")
fname=file.choose()
data=read.csv(fname,header=T)
